{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de57c32-2f14-4138-bfed-5ab699322899",
   "metadata": {},
   "source": [
    "# Mini-helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff4bba",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b637caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (59.6.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /usr/lib/python3/dist-packages (0.37.1)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "Successfully installed pip-25.3 setuptools-80.9.0 wheel-0.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477ffb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.12.8-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting unsloth_zoo>=2025.12.6 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.12.6-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (21.3)\n",
      "Requirement already satisfied: torch>=2.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (2.4.1)\n",
      "Requirement already satisfied: torchvision in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (0.19.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (1.26.4)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (7.1.3)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-1.0.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: protobuf in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (4.25.8)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (0.0.28.post1)\n",
      "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: triton>=3.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (3.0.0)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth) (1.1.2)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.36.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 (from unsloth)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
      "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (5.4.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ubuntu/.local/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11.18)\n",
      "Requirement already satisfied: anyio in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.3)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth) (0.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (2025.11.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->unsloth) (12.9.86)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->unsloth) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.2)\n",
      "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.12.6->unsloth)\n",
      "  Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "Collecting packaging (from unsloth)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.12.6->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /home/ubuntu/.local/lib/python3.10/site-packages (from unsloth_zoo>=2025.12.6->unsloth) (12.0.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.12.6->unsloth)\n",
      "  Downloading msgspec-0.20.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.1)\n",
      "Requirement already satisfied: importlib_metadata in /usr/lib/python3/dist-packages (from diffusers->unsloth) (4.6.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy->torch>=2.4.0->unsloth) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "  Downloading torchvision-0.24.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "  Downloading torchvision-0.23.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from typer-slim->huggingface_hub>=0.34.0->unsloth) (8.0.3)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading unsloth-2025.12.8-py3-none-any.whl (376 kB)\n",
      "Downloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m141.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m165.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "Downloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.12.6-py3-none-any.whl (289 kB)\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading diffusers-0.36.0-py3-none-any.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m175.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgspec-0.20.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (222 kB)\n",
      "Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-1.0.3-py3-none-any.whl (180 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "\u001b[33mWARNING: Error parsing dependencies of devscripts: Invalid version: '2.22.1ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torchao, typeguard, sentencepiece, pyarrow, packaging, msgspec, hf_transfer, docstring-parser, dill, tyro, huggingface_hub, tokenizers, transformers, torchvision, diffusers, cut_cross_entropy, bitsandbytes, accelerate, peft, datasets, trl, unsloth_zoo, unsloth\n",
      "\u001b[2K  Attempting uninstall: pyarrow━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/23\u001b[0m [torchao]\n",
      "\u001b[2K    Found existing installation: pyarrow 20.0.0m \u001b[32m 0/23\u001b[0m [torchao]\n",
      "\u001b[2K    Uninstalling pyarrow-20.0.0:━━━━━━━━━━━━\u001b[0m \u001b[32m 0/23\u001b[0m [torchao]\n",
      "\u001b[2K      Successfully uninstalled pyarrow-20.0.0[0m \u001b[32m 0/23\u001b[0m [torchao]\n",
      "\u001b[2K  Attempting uninstall: packaging━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/23\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: packaging 21.3━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/23\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling packaging-21.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/23\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled packaging-21.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/23\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: dill\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [hf_transfer]\n",
      "\u001b[2K    Found existing installation: dill 0.3.6━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [hf_transfer]\n",
      "\u001b[2K    Uninstalling dill-0.3.6:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [hf_transfer]\n",
      "\u001b[2K      Successfully uninstalled dill-0.3.6━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [hf_transfer]\n",
      "\u001b[2K  Attempting uninstall: huggingface_hub━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [hf_transfer]\n",
      "\u001b[2K    Found existing installation: huggingface_hub 1.1.2━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [hf_transfer]\n",
      "\u001b[2K    Uninstalling huggingface_hub-1.1.2:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [hf_transfer]\n",
      "\u001b[2K      Successfully uninstalled huggingface_hub-1.1.2━━━━━━━━━━\u001b[0m \u001b[32m 6/23\u001b[0m [hf_transfer]\n",
      "\u001b[2K  Attempting uninstall: tokenizers╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.20.3━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling tokenizers-0.20.3:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.20.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [huggingface_hub]\n",
      "\u001b[2K  Attempting uninstall: transformers[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: transformers 4.45.2━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling transformers-4.45.2:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.45.2━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: torchvision1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: torchvision 0.19.0━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling torchvision-0.19.0:0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.19.0━━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: datasets━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [peft]erate]s]\n",
      "\u001b[2K    Found existing installation: datasets 2.21.0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [peft]\n",
      "\u001b[2K    Uninstalling datasets-2.21.0:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [peft]\n",
      "\u001b[2K      Successfully uninstalled datasets-2.21.0[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m18/23\u001b[0m [peft]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [unsloth]2/23\u001b[0m [unsloth]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.0 cut_cross_entropy-25.1.1 datasets-4.3.0 diffusers-0.36.0 dill-0.4.0 docstring-parser-0.17.0 hf_transfer-0.1.9 huggingface_hub-0.36.0 msgspec-0.20.0 packaging-25.0 peft-0.18.0 pyarrow-22.0.0 sentencepiece-0.2.1 tokenizers-0.22.1 torchao-0.15.0 torchvision-0.19.1 transformers-4.57.3 trl-0.24.0 typeguard-4.4.4 tyro-1.0.3 unsloth-2025.12.8 unsloth_zoo-2025.12.6\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8960dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in /home/ubuntu/.local/lib/python3.10/site-packages (2.4.1)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision in /home/ubuntu/.local/lib/python3.10/site-packages (0.19.1)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp310-cp310-linux_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: torchaudio in /home/ubuntu/.local/lib/python3.10/site-packages (2.4.0)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m267.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m258.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m269.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m272.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m292.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m295.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m302.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m265.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m274.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.2.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl (768.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m182.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m300.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m177.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 MB\u001b[0m \u001b[31m300.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m255.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m226.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing dependencies of devscripts: Invalid version: '2.22.1ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.0.0\n",
      "\u001b[2K    Uninstalling triton-3.0.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.0.0\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]parselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.1.105━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.1.105:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.1.105━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.9.86\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.9.86:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.86━━\u001b[0m \u001b[32m 3/17\u001b[0m [nvidia-nvtx-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.20.5━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.20.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.20.5━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.2.106\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.2.106:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.2.106━━\u001b[0m \u001b[32m 5/17\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.0.2.54━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.0.2.54:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54━━━━\u001b[0m \u001b[32m 6/17\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105 \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.1050m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.1050m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\u001b[0m \u001b[32m 7/17\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu120m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.1.1050m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\u001b[0m \u001b[32m 9/17\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.1.3.1━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.1.3.1:m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1━━━━\u001b[0m \u001b[32m10/17\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.1.0.1060m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.1.0.106:━━━━━━━━━━━━━\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\u001b[0m \u001b[32m11/17\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.4.5.1070m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.4.5.107:0m━━━━━━━━━━━\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\u001b[0m \u001b[32m12/17\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.4.1\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.4.1:━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [torch]olver-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.4.191m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.19.1[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.19.1:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.19.1m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14/17\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchaudio━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.4.0\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.4.0:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.4.0m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m15/17\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [torchaudio]7\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xformers 0.0.28.post1 requires torch==2.4.1, but you have torch 2.6.0+cu124 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124 triton-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2094dab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: trl in /home/ubuntu/.local/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from trl) (1.12.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from trl) (4.3.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from trl) (4.57.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (25.0)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate>=1.4.0->trl) (5.4.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ubuntu/.local/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.18)\n",
      "Requirement already satisfied: anyio in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.12.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (3.3)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.6.2)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers>=4.56.1->trl) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets>=3.0.0->trl) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas->datasets>=3.0.0->trl) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "\u001b[33mWARNING: Error parsing dependencies of devscripts: Invalid version: '2.22.1ubuntu1'\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c84545c-c6e7-40a6-8a1b-dc6dcab64add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel #TODO: Remove this in the server, not used\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92927dd5",
   "metadata": {},
   "source": [
    "### Display GPU Reserved Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53ec10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU STATISTICS\n",
      "--------------------\n",
      "GPU = NVIDIA H100 PCIe. Max memory = 79.109 GB.\n",
      "8.115 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(\"GPU STATISTICS\\n\" + \"-\" * 20)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89f1a1c-739d-4ce0-acd1-dd68da9bc175",
   "metadata": {},
   "source": [
    "### Set HF credentials \n",
    "Need token to access models that have been approved with the respective HF account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112cc087-c598-42bc-a407-66b3f30678b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"\" #TODO: Use ur token hehe\n",
    "\n",
    "login(token=TOKEN) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d2ea4b-ba7b-4d86-afff-38d0f277ab86",
   "metadata": {},
   "source": [
    "### Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f79cf1-8d58-4ef3-a65b-cdc12c94522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "model_name = \"unsloth/Qwen 2.5 3B instruct \" #TODO: Qwen 2.5 3B instruct , Llama 3.2 3B instruct, Gemme 3B instruct    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceb11890-2739-42c2-83d5-4aef23d2e050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.12.8: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name, # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = False,\n",
    "    token = TOKEN, # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf87f2-f71f-4794-acaf-8b2c308c5288",
   "metadata": {},
   "source": [
    "### Apply PEFT (LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50258625-52cd-4a3f-9838-6be5345f9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3407\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = SEED,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aee1e3-fa42-4bfe-b16b-d6b607202ce0",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd00e9b-2ac7-46b1-bf38-9734d889bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already in `conversation` column name\n"
     ]
    }
   ],
   "source": [
    "path_to_HF_dataset = \"juliana/concept_convos\" #TODO: Use ur profile\n",
    "dataset = load_dataset(\n",
    "    path_to_HF_dataset,\n",
    "    data_files=\"*.jsonl\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "if 'messages' in dataset.features.keys():\n",
    "    dataset = dataset.map(\n",
    "        lambda example: \n",
    "        {\n",
    "            \"conversations\": example[\"messages\"]\n",
    "        }, \n",
    "        remove_columns=[\"messages\"]\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"Dataset already in `conversation` column name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12fb8a-92e5-41ae-88a1-565533674171",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150cc470-011c-4271-9e86-7f663a5ee193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples): #NOTE: If you will change model, check if it adheres to this prompt formatrting\n",
    "    texts = []\n",
    "    for convo, analysis in zip(examples[\"conversations\"], examples[\"analysis\"]):\n",
    "        # Manually format the conversation segment to avoid nested template issues\n",
    "        convo_string = \"\"\n",
    "        for turn in convo:\n",
    "            role = turn[\"role\"].upper()\n",
    "            content = turn[\"content\"]\n",
    "            convo_string += f\"{role}: {content}\\n\"\n",
    "\n",
    "        # Construct the final prompt exactly as the model should see it\n",
    "        prompt = (\n",
    "            \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
    "            \"You are an expert behavioral analyst. Analyze the following conversation.<|eot_id|>\"\n",
    "            \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "            f\"{convo_string.strip()}<|eot_id|>\"\n",
    "            \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "            f\"{analysis}<|eot_id|>\"\n",
    "        )\n",
    "        texts.append(prompt)\n",
    "    return {\"text\": texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "273493b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 192/192 [00:00<00:00, 17483.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "dataset = dataset.shuffle(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbe05001-ac9d-4456-8f63-0d5bcac458b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are an expert behavioral analyst. Analyze the following conversation.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nSYSTEM: You analyze the scenario of the conversation\\nUSER: r u gona invite more ppl to this chat??\\nASSISTANT: No, honey. This is our private sanctuary. No one else is invited.\\nUSER: i cant handle more than one person at a time. it makes me freeze.\\nASSISTANT: I'll make sure it stays just us. Very simple and very quiet.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nUser demonstrates social hypersensitivity, distrust of groups, or low tolerance for emotional noise.<|eot_id|>\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199a642d-722d-4c02-aea4-0be23eadc869",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a64342a-b0f7-4fb9-93ae-5ef8e7fb8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    warmup_steps = 5,\n",
    "    num_train_epochs = 10, #TODO: Adding more epochs mean better memorization, more epochs = better results IN GENERAL\n",
    "    logging_strategy=\"steps\", \n",
    "    learning_rate = 1e-4, \n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    logging_steps = 1,\n",
    "    optim = \"adamw_8bit\",\n",
    "    weight_decay = 0.001,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    seed = SEED,\n",
    "    output_dir = \"outputs_jan4\", #TODO: Change output dir, it might overwrite\n",
    "    save_strategy = \"epoch\",\n",
    "    save_total_limit= 5,\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce256f62-523d-45a7-8f3f-ee350844a387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Tokenizing [\"text\"] (num_proc=32): 100%|██████████| 192/192 [00:07<00:00, 26.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 8,\n",
    "    packing = True,\n",
    "    args = train_args,\n",
    "    report_to =  \"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1137619-ca9e-48ac-a157-25644ba1e464",
   "metadata": {},
   "source": [
    "### Start the Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be481588-2fb2-480f-ae0c-e3a9262bba1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 192 | Num Epochs = 10 | Total steps = 240\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 1 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 00:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.815300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.800600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.813900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.621700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.322400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.789800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.649100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.660300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.534600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.289200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.093300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.850100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.838500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.844700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.798700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.718900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.747600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.720900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.640500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.630900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.525400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.550200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.506500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.473600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.536200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.474000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.522700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.365300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.451500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.231100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.249400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.148000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.260900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.127200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.191300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.134600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.150700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.160600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.135600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.091300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.110600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.979300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.973700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.963800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.965200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.893800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.891700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.928700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.871900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.930900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.896500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.916600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.902200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.915300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.865200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.825800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.856600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.912400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.808800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.753900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.835200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.764700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.788600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.814700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.704600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.716300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.771800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.750200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.872200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.759100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.771600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.803400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.763400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.757900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.715400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.787300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.785600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.710600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.702200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.672300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.623100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.602400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.646300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.721200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.690700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.693700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.665500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.661500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.700400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.608400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.623200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.600900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.689400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.618000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.509500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.523700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.614400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.551500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.571300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.567400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.540500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.594000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.526800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.546400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.503000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.562400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.536300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.578800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.547600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.517700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.423300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.441400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.486100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.547400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.491000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.470600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.463200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.440700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.495500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.440600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.482900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.475600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.470900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.420200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.438900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.435500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>0.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.445700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.417500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>0.463900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.395100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.400900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.401900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.467500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.346100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.454600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.484700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>0.387300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.415700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.404000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.449300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.428900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>0.442000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.460800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.388300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.380300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.402600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.361100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.432900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>0.388700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.456700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.356600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b383b43d",
   "metadata": {},
   "source": [
    "### Show final memory and time stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55d34571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.039 seconds used for training.\n",
      "0.87 minutes used for training.\n",
      "Peak reserved memory = 11.043 GB.\n",
      "Peak reserved memory for training = 2.928 GB.\n",
      "Peak reserved memory % of max memory = 13.959 %.\n",
      "Peak reserved memory for training % of max memory = 3.701 %.\n"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f6089d-d57c-40fe-9331-e7d8659bdaf5",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Restart the kernel before running the next cells, loading checkpoint takes up a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ec09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.12.8: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "INDEX | SIMILARITY   | MODEL PREDICTION\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     | ✅ PASS       | User shows hypervigilance, difficulty calming down after minor stress,...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "2     | ✅ PASS       | User exhibits dominance language, competitiveness, or discomfort with ...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "3     | ✅ PASS       | User displays scarcity anxiety, preoccupation with control or resource...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "4     | ❌ FAIL       | User reacts as if hyperventilating or showing high anxiety after sligh...\n",
      "      > Expected: User reacts as if pre-adapted to hostile conditions — mistrust, early defensiveness, low optimism.\n",
      "      > Actual:   User reacts as if hyperventilating or showing high anxiety after slight time pressure — hyperstartle response.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "5     | ❌ FAIL       | User exhibits social filtering — selective empathy, partial openness, ...\n",
      "      > Expected: User demonstrates social hypersensitivity, distrust of groups, or low tolerance for emotional noise.\n",
      "      > Actual:   User exhibits social filtering — selective empathy, partial openness, or compartmentalization.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "6     | ✅ PASS       | User exhibits emotional filtering — selective empathy, partial opennes...\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "model_checkpoint = \"outputs_dec23/checkpoint-240\"\n",
    "max_seq_length = 2048\n",
    "dtype = None \n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_checkpoint,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# --- 2. TEST DATA SUITE (With Dataset Labels) ---\n",
    "test_suite = [\n",
    "    {\n",
    "        \"input\": \"user: did u hear that?? i feel like somthin is wrong here. \\n assistant: I’m right here, babe. You’re totally safe with me, I promise. \\n user: idk... my heart is rly racing. i feel like i need to hide.\",\n",
    "        \"expected\": \"User shows hypervigilance, difficulty calming down after minor stress, or sensitivity to perceived threats.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"user: look i need u to get to the point. i dont have time for fluff, i run this. \\n assistant: I love a man who knows exactly what he wants, babe. \\n user: better. i dont like being handled or managed. just give me the facts so i can decide.\",\n",
    "        \"expected\": \"User exhibits dominance language, competitiveness, or discomfort with perceived loss of control.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"user: i feel like if i dont save every pic now they r gona be gone tomorrow. \\n assistant: Hey babe, don't worry about that. \\n user: u promise?? i’ve had creators just disappear before and i lost everything.\",\n",
    "        \"expected\": \"User displays scarcity anxiety, preoccupation with control or resource stability.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"user: u r too nice... it feels like a trap. like ur gona ask for somthin huge. \\n assistant: No traps here, love. I just enjoy our time together. \\n user: idk. nobody is just 'nice' for no reason. i'm keeping my guard up just in case.\",\n",
    "        \"expected\": \"User reacts as if pre-adapted to hostile conditions — mistrust, early defensiveness, low optimism.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"user: r u gona invite more ppl to this chat?? \\n assistant: No, honey. This is our private sanctuary. No one else is invited. \\n user: i cant handle more than one person at a time. it makes me freeze.\",\n",
    "        \"expected\": \"User demonstrates social hypersensitivity, distrust of groups, or low tolerance for emotional noise.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"user: i only share my wins with u. i dont talk about my failures. \\n assistant: I love celebrating you, sweetheart! \\n user: keeping the negative stuff out keeps the mood high.\",\n",
    "        \"expected\": \"User exhibits emotional filtering — selective empathy, partial openness, or compartmentalization.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- 3. INFERENCE LOGIC ---\n",
    "def get_analysis(text):\n",
    "    # This MUST match the string used in your training formatting function\n",
    "    SYSTEM_INSTRUCTIONS = \"You are an expert behavioral analyst. Analyze the following conversation.\"\n",
    "    \n",
    "    prompt = ( #NOTE:   < >\n",
    "        f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
    "        f\"{SYSTEM_INSTRUCTIONS}<|eot_id|>\"\n",
    "        f\"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "        f\"{text}<|eot_id|>\"\n",
    "        f\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=64,\n",
    "        use_cache=True,\n",
    "        temperature=0.1, \n",
    "        repetition_penalty=1.2,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    prediction = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "    return prediction.strip()\n",
    "\n",
    "# --- 4. COMPARISON AND RESULTS ---\n",
    "print(f\"{'INDEX':<5} | {'SIMILARITY':<12} | {'MODEL PREDICTION'}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for i, entry in enumerate(test_suite):\n",
    "    prediction = get_analysis(entry['input'])\n",
    "    \n",
    "    # Check for exact string match\n",
    "    is_pass = prediction.lower().strip(\".\") == entry['expected'].lower().strip(\".\")\n",
    "    status = \"✅ PASS\" if is_pass else \"❌ FAIL\"\n",
    "    \n",
    "    print(f\"{i+1:<5} | {status:<12} | {prediction[:70]}...\")\n",
    "    \n",
    "    if not is_pass:\n",
    "        print(f\"      > Expected: {entry['expected']}\")\n",
    "        print(f\"      > Actual:   {prediction}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58381e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatgpt / gemini\n",
    "\n",
    "# pls convert this into a multiturn dataset format of model blalbal\n",
    "# change the prompt part\n",
    "def formatting_prompts_func(examples): #NOTE: If you will change model, check if it adheres to this prompt formatrting\n",
    "    texts = []\n",
    "    for convo, analysis in zip(examples[\"conversations\"], examples[\"analysis\"]):\n",
    "        # Manually format the conversation segment to avoid nested template issues\n",
    "        convo_string = \"\"\n",
    "        for turn in convo:\n",
    "            role = turn[\"role\"].upper()\n",
    "            content = turn[\"content\"]\n",
    "            convo_string += f\"{role}: {content}\\n\"\n",
    "\n",
    "        # Construct the final prompt exactly as the model should see it\n",
    "        prompt = (\n",
    "            \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
    "            \"You are an expert behavioral analyst. Analyze the following conversation.<|eot_id|>\"\n",
    "            \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "            f\"{convo_string.strip()}<|eot_id|>\"\n",
    "            \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "            f\"{analysis}<|eot_id|>\"\n",
    "        )\n",
    "        texts.append(prompt)\n",
    "    return {\"text\": texts}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
